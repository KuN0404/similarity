Deteksi Serangan Data Exfiltration pada MariaDB
Menggunakan Isolation Forest
Khusnul Khotimaha,1*, Hartonoa,2, Farisa,3
1khusnul.khotimah@umko.ac.id, 2hartono@umko.ac.id, 3faris@umko.ac.id
aUniversitas Muhammadiyah Kotabumi

Abstract
This study implements an anomaly detection method using Isolation Forest to identify potential data exfiltration attacks in network traffic. Data exfiltration is a serious cyber threat, characterized by the transfer of sensitive data in unusual volumes or patterns. Isolation Forest was chosen for its effectiveness in detecting outliers in large datasets without requiring anomaly labels. The main objective of this research is to build and evaluate an Isolation Forest-based anomaly detection model for network traffic, with a specific focus on identifying patterns related to database exfiltration (MariaDB/MySQL). The study involves stages of collecting and merging benign network traffic datasets, conducting exploratory data analysis (EDA) to understand data characteristics, and preprocessing data including feature engineering to extract relevant information such as time-based features, frequency, and packet length characteristics. The methods used include merging benign data, removing irrelevant columns, extracting timestamp and network features, and encoding categorical features. The dataset is then divided into training data (80%) and testing data (20%). The Isolation Forest model is trained on the standardized training data. Evaluation is performed on an internal (benign) test set and an external test set simulated to contain database exfiltration traffic. Additionally, specific categorization functions are developed for protocols, packet length patterns, and destinations relevant to database exfiltration, as well as a database-specific risk assessment scheme. Evaluation results show an internal accuracy of 94.84% on benign data and a 100% detection rate on simulated exfiltration data, resulting in a combined accuracy of 94.92%. The combined confusion matrix shows the model successfully detected all simulated exfiltration cases (True Positive = 67) but produced a number of False Positives (228) on benign data. Analysis of specific database patterns indicates that direct protocols (MYSQL/MARIADB), large data transfers, and suspicious destinations (such as cloud storage or external servers) have high database risk scores. The conclusion of this study is that the Isolation Forest model, combined with feature engineering and database-specific categorization, can detect data exfiltration patterns, especially those related to databases, with a high detection rate. Although there are False Positives that need to be minimized, this approach is promising for strengthening anomaly detection systems in complex network environments.
Keywords: Data Exfiltration, Isolation Forest, Maria DB, Anomaly Detection

Abstrak
Penelitian ini mengimplementasikan metode deteksi anomali menggunakan Isolation Forest untuk mengidentifikasi potensi serangan data exfiltration pada lalu lintas jaringan. Data exfiltration merupakan ancaman siber yang serius, ditandai dengan transfer data sensitif dalam volume atau pola yang tidak biasa. Isolation Forest dipilih karena efektivitasnya dalam mendeteksi outlier pada dataset besar tanpa memerlukan label anomali. Tujuan utama penelitian ini adalah membangun dan mengevaluasi model deteksi anomali berbasis Isolation Forest untuk lalu lintas jaringan, dengan fokus khusus pada identifikasi pola yang terkait dengan database exfiltration (MariaDB/MySQL). Penelitian ini melibatkan tahap pengumpulan dan penggabungan dataset lalu lintas jaringan benign, eksplorasi data (EDA) untuk memahami karakteristik data, dan pra-pemrosesan data termasuk rekayasa fitur (feature engineering) untuk mengekstraksi informasi relevan seperti fitur berbasis waktu, frekuensi, dan karakteristik panjang paket. Metode yang digunakan meliputi penggabungan data benign, penghapusan kolom yang tidak relevan, ekstraksi fitur timestamp dan jaringan, serta encoding fitur kategorikal. Dataset kemudian dibagi menjadi data training (80%) dan testing (20%). Model Isolation Forest dilatih pada data training yang telah distandardisasi. Evaluasi dilakukan pada test set internal (benign) dan test set eksternal yang disimulasikan mengandung lalu lintas exfiltration database. Selain itu, dikembangkan fungsi kategorisasi khusus untuk protokol, pola panjang paket, dan tujuan yang relevan dengan database exfiltration, serta skema penilaian risiko spesifik database. Hasil evaluasi menunjukkan akurasi internal sebesar 94.84% pada data benign dan detection rate 100% pada data exfiltration simulasi, menghasilkan akurasi gabungan 94.92%. Confusion matrix gabungan menunjukkan model berhasil mendeteksi semua kasus exfiltration simulasi (True Positive = 67) namun menghasilkan sejumlah False Positive (228) pada data benign. Analisis pola spesifik database menunjukkan bahwa protokol langsung (MYSQL/MARIADB), transfer data besar, dan tujuan mencurigakan (seperti cloud storage atau server eksternal) memiliki skor risiko database yang tinggi. Kesimpulan dari penelitian ini adalah model Isolation Forest yang dikombinasikan dengan rekayasa fitur dan kategorisasi spesifik database mampu mendeteksi pola data exfiltration, khususnya yang terkait dengan database, dengan tingkat deteksi yang tinggi. Meskipun terdapat False Positive yang perlu diminimalkan, pendekatan ini menjanjikan untuk memperkuat sistem deteksi anomali dalam lingkungan jaringan yang kompleks.
Kata Kunci: Data Exfiltration, Isolation Forest, Maria DB, Anomaly Detection

PENDAHULUAN
Keamanan siber telah menjadi isu krusial dalam era digital saat ini, seiring dengan semakin meningkatnya ketergantungan organisasi dan individu terhadap infrastruktur teknologi informasi. Salah satu ancaman siber yang paling merusak dan sulit dideteksi adalah data exfiltration. Data exfiltration, juga dikenal sebagai pencurian data atau kebocoran data, merujuk pada pelanggaran keamanan di mana terjadi transfer atau pengambilan informasi pribadi tanpa otorisasi dari sebuah komputer atau server [1], [2], [3], [4]. Serangan ini dapat dilakukan oleh aktor internal (insider threats) maupun eksternal (advanced persistent threats - APTs) dan sering kali menjadi tahap akhir dari serangan siber yang kompleks, setelah berhasil mendapatkan akses awal dan melakukan pengintaian di dalam sistem target [5], [6], [7]. Masalah data exfiltration sangat penting untuk  karena konsekuensi serius yang ditimbulkannya. Data sensitif dapat berupa informasi keuangan, kekayaan intelektual, data pribadi pelanggan (seperti yang diatur dalam peraturan privasi data seperti GDPR atau UU ITE di Indonesia), rahasia dagang, atau informasi strategis lainnya. Kebocoran atau pencurian data semacam ini dapat mengakibatkan kerugian finansial yang besar akibat denda regulasi, biaya remediasi, tuntutan hukum, serta hilangnya kepercayaan pelanggan dan reputasi organisasi. Tidak hanya itu, dalam skala yang lebih luas, data exfiltration terhadap infrastruktur kritis atau data pemerintah dapat mengancam keamanan nasional [8].

Deteksi data exfiltration bukanlah hal yang mudah untuk dilakukan karena pelaku seringkali berusaha menyamarkan aktivitas mereka agar terlihat seperti lalu lintas jaringan yang normal [9], [10]. Untuk mengatasi tantangan ini, salah satu pendekatan yang berkembang adalah dengan berfokus pada analisis agregat metadata jaringan daripada inspeksi konten paket secara mendalam. Pendekatan berbasis metadata ini tidak hanya lebih menjaga privasi, tetapi juga lebih efisien untuk menangani volume data yang masif [11], [12], [13].  Teknik penyembunyian yang umum digunakan meliputi:
Tunneling merupakan metode penyaluran data melalui protokol standar yang umumnya tidak dimanfaatkan untuk transfer berukuran besar, seperti DNS, ICMP, atau HTTP/HTTPS dengan manipulasi header maupun payload. DNS tunneling bahkan dipandang sebagai salah satu teknik kebocoran data paling signifikan saat ini karena memungkinkan penyisipan informasi rahasia ke dalam paket DNS untuk melewati mekanisme keamanan [14]. Mengingat lalu lintas DNS jarang diblokir demi menjaga kelancaran resolusi nama domain, protokol ini kerap dieksploitasi sebagai saluran tersembunyi (covert channel) [14]. Hal ini disebabkan karena layanan DNS merupakan salah satu layanan fundamental di internet, sehingga administrator jaringan tidak dapat dengan mudah menutup port 53 (UDP/TCP) pada fasilitas keamanan seperti firewall atau IDS (Ichise dkk. 2025).
Fragmentation mengacu pada pemecahan data menjadi paket-paket kecil yang dikirimkan perlahan dari waktu ke waktu (low-and-slow exfiltration). Strategi ini dirancang agar lalu lintas tetap berada di bawah ambang batas deteksi volume oleh sistem keamanan[16], [17].
Encryption digunakan dengan cara mengenkripsi data sensitif sebelum dikirimkan, sehingga isi komunikasi tidak dapat diinspeksi oleh mekanisme tradisional seperti Intrusion Prevention Systems (IPS). Walaupun enkripsi merupakan praktik keamanan yang umum, pengiriman data terenkripsi dalam jumlah besar ke alamat tujuan yang tidak lazim sering menjadi indikator aktivitas exfiltration [18].
Steganography adalah penyembunyian data di dalam media lain, misalnya file gambar atau audio, maupun pada field tertentu dari sebuah protokol yang tidak biasanya dimanfaatkan[19], [20].
Pemanfaatan layanan legitimasi terjadi ketika pelaku menggunakan layanan sah seperti cloud storage (Dropbox, Google Drive, AWS S3), email, atau platform kolaborasi untuk menyelundupkan data yang dicuri. Aktivitas semacam ini seringkali sulit dibedakan dari penggunaan normal oleh pengguna sah[21].

Secara umum, metode-metode data exfiltration ini dapat dikategorikan menjadi tiga kelompok utama yaitu metode berbasis konten (seperti menyembunyikan data dalam pesan error HTTP 404 atau steganography gambar), metode berbasis header (seperti memanipulasi field TTL atau IP Options pada paket data), dan metode berbasis meta (seperti mengontrol waktu pengiriman paket) [2], [22], [23]. Metode deteksi tradisional berbasis signature (tanda tangan) atau rule-based (aturan) seringkali tidak efektif dalam mendeteksi serangan data exfiltration yang baru atau bermodifikasi. Pendekatan ini, yang sering disebut sebagai Indicators of Compromise (IoC), mungkin tidak selalu menangkap penuh dari sebuah ancaman atau kampanye serangan siber, sehingga berpotensi menyebabkan banyaknya peringatan palsu dan kegagalan deteksi (Preuveneers dkk. 2021). Selain itu, nilai dari IoC dapat menurun seiring waktu karena sifatnya yang tidak stabil, misalnya ketika penyerang berpindah alamat IP untuk menghindari deteksi [24]. Signature hanya dapat mendeteksi pola serangan yang sudah diketahui, sementara rule-based memerlukan pengetahuan mendalam tentang perilaku normal dan anomali, yang sulit didefinisikan secara komprehensif dalam lingkungan jaringan yang dinamis. Upaya penanggulangan data exfiltration secara umum dapat diklasifikasikan menjadi dua jenis, yaitu metode preventif (mencegah di tahap awal) dan detektif (mendeteksi saat serangan terjadi). Sementara metode tradisional berbasis signature gagal mengidentifikasi serangan baru atau zero-day, teknik berbasis Machine Learning telah diusulkan untuk membuat prediksi secara otomatis dan real-time [9], [10], [25]. Oleh karena itu, pendekatan deteksi anomali (anomaly detection) menjadi semakin relevan.

Deteksi anomali berfokus pada identifikasi pola atau perilaku yang menyimpang secara signifikan dari "normal". Dalam konteks data exfiltration, anomali dapat berupa volume data yang tiba-tiba meningkat dari sumber tertentu ke tujuan yang tidak biasa, penggunaan protokol yang tidak sesuai kebiasaan, transfer data pada jam-jam yang tidak lazim, atau kombinasi dari beberapa indikator tersebut. Machine learning, khususnya metode unsupervised learning, sangat cocok untuk tugas ini karena tidak memerlukan dataset berlabel anomali yang seringkali langka dan sulit diperoleh. Salah satu algoritma unsupervised learning yang efektif untuk deteksi anomali adalah Isolation Forest. Isolation Forest bekerja dengan membangun pohon keputusan (decision trees) secara acak untuk mengisolasi setiap titik data. Anomali, yang merupakan titik data yang jarang dan berbeda dari mayoritas, cenderung lebih mudah diisolasi (membutuhkan jalur yang lebih pendek dalam pohon) dibandingkan titik data normal. Keunggulan Isolation Forest antara lain kemampuannya menangani data berdimensi tinggi, skalabilitas yang relatif baik untuk dataset besar, dan tidak membutuhkan asumsi distribusi data seperti metode berbasis jarak (misalnya K-Means clustering). Algoritma ini memang dirancang untuk mengisolasi anomali alih-alih memprofilkan titik normal, sehingga efektif untuk data dengan dimensi tinggi maupun tipe variabel yang beragam [26], [27]. Algoritma ini juga bekerja dengan cara yang ringan secara komputasi, artinya tidak membutuhkan banyak waktu atau sumber daya, sehingga cocok untuk digunakan pada sistem sekala kecil hingga besar atau infrastruktur penting yang harus selalu berjalan lancar [10], [28]

Meskipun Isolation Forest telah terbukti efektif dalam berbagai aplikasi deteksi anomali, penerapannya dalam deteksi data exfiltration, khususnya yang menargetkan data dari  database seperti MariaDB/MySQL, masih menghadapi tantangan spesifik. Lalu lintas  database memiliki karakteristik unik, termasuk penggunaan protokol spesifik (seperti protokol MySQL), pola komunikasi klien-server yang terstruktur, dan potensi transfer data dalam volume besar (misalnya saat replikasi, backup, atau query besar). Exfiltration data dari  database seringkali melibatkan eksploitasi kerentanan SQL Injection atau akses tidak sah ke server  database, diikuti dengan transfer data dalam jumlah besar. Namun, jika deteksi hanya difokuskan pada satu jalur tertentu, misalnya pemantauan lalu lintas jaringan saja, maka penyerang tetap dapat mencari cara lain untuk mengalirkan data keluar. Hal ini menunjukkan pentingnya strategi deteksi yang menyeluruh dan tidak terbatas pada satu sudut pandang saja [1], [4], [10], [29].

PENELITIAN SEBELUMNYA
Penelitian dalam bidang deteksi anomali lalu lintas jaringan telah berkembang pesat.  Isolation Forest adalah salah satu metode deteksi anomali berbasis unsupervised machine learning yang dirancang untuk mengidentifikasi data yang menyimpang secara signifikan dari mayoritas data lainnya (Ragil Saputro dkk. 2025). Prinsip dasar dari algoritma ini adalah bahwa anomali merupakan titik data yang lebih mudah untuk diisolasi dibandingkan dengan data normal (Santoso dkk. 2024). Hal ini disebabkan karena data anomali cenderung berada pada titik yang jarang muncul dalam dataset dan berada jauh dari kumpulan data utama [30]. Deteksi anomali lalu lintas jaringan telah banyak diteliti dengan memanfaatkan metode machine learning. Pendekatan yang umum digunakan meliputi Support Vector Machines (SVM), algoritme clustering seperti K-Means dan DBSCAN, maupun metode berbasis statistik.
Namun, sebagian besar penelitian masih berfokus pada deteksi serangan Denial of Service (DoS), Distributed Denial of Service (DDoS) atau probing, sementara aspek deteksi data exfiltration dengan karakteristik low-and-slow maupun tunneling relatif kurang mendapat perhatian. Deteksi data exfiltration menjadi topik yang mulai memperoleh perhatian khusus dalam beberapa studi. Salah satu fase krusial sebelum terjadinya exfiltration adalah komunikasi Command and Control (C&C), ketika malware yang menginfeksi komputer di jaringan mencoba terhubung ke server C&C penyerang untuk menerima instruksi [15].
Perangkat yang terinfeksi cenderung berkomunikasi langsung dengan server C&C menggunakan protokol DNS, sebuah perilaku yang menyimpang dari lalu lintas DNS normal yang seharusnya melalui DNS resolver internal [15]. Pendekatan yang digunakan bervariasi, mulai dari analisis aliran data (flow analysis), inspeksi paket mendalam (deep packet inspection - DPI), hingga penggunaan machine learning untuk mengidentifikasi pola transfer data yang tidak biasa, tujuan yang mencurigakan, atau penggunaan protokol yang tidak standar misalnya DNS tunneling detection. Literatur spesifik mengenai deteksi exfiltration dari database MariaDB/MySQL menggunakan anomali berbasis lalu lintas masih terbatas. Feature engineering untuk lalu lintas jaringan memiliki peran penting karena kualitas fitur secara langsung memengaruhi kinerja model machine learning. Penelitian ini memanfaatkan sejumlah fitur umum, antara lain volume data (Length), frekuensi komunikasi (Source/Destination frequency), serta atribut berbasis waktu (timestamp, hour, day_of_week) yang terbukti relevan untuk mendeteksi anomali temporal maupun volumetrik. Transformasi logaritmik pada fitur Length (length_log) diterapkan untuk mengurangi skewness data, sedangkan rolling statistics seperti length_rolling_mean dan length_rolling_std digunakan untuk menangkap dinamika perubahan pola volume data dari waktu ke waktu. Dengan mengintegrasikan kekuatan algoritma Isolation Forest dalam mendeteksi outlier dengan rekayasa fitur dan analisis pola yang spesifik untuk lalu lintas database MariaDB/MySQL, penelitian ini berharap dapat memberikan kontribusi dalam meningkatkan kemampuan deteksi dini serangan data exfiltration yang semakin canggih dan tersembunyi. Langkah-langkah selanjutnya dalam penelitian ini akan melibatkan implementasi model, evaluasi mendalam, dan analisis hasil deteksi anomali dalam konteks risiko database exfiltration.

Meskipun penelitian sebelumnya telah banyak membahas deteksi anomali pada lalu lintas jaringan secara umum, terdapat kesenjangan dalam literatur terkait deteksi data exfiltration yang spesifik menargetkan data dari database (misalnya MariaDB/MySQL). Upaya deteksi anomali pada lalu lintas database diawali dengan proses identifikasi perbedaan antara aktivitas normal dan indikasi exfiltration data [10], [22]. Tantangan utama muncul karena komunikasi umumnya berlangsung melalui protokol standar, seperti TCP/IP, atau dalam bentuk terenkripsi menggunakan TLS/SSL. Kondisi ini menyebabkan pola komunikasi yang tampak sah dapat menyembunyikan aktivitas berbahaya, sehingga pemisahan yang akurat antara lalu lintas benign dan anomali menjadi aspek yang krusial. Selanjutnya, analisis pola lalu lintas database menuntut pengembangan fitur dan metode analisis yang memiliki sensitivitas tinggi terhadap karakteristik unik interaksi basis data. Hal ini mencakup identifikasi query yang tidak lazim, transfer data dalam jumlah besar yang terjadi di luar jadwal rutin backup atau replikasi, serta koneksi yang terarah ke tujuan eksternal yang tidak sesuai dengan praktik operasional.
Pendekatan ini berupaya untuk menangkap deviasi halus yang berpotensi merepresentasikan aktivitas exfiltration. Selain itu, peningkatan akurasi deteksi dapat dicapai melalui integrasi pengetahuan domain basis data. Informasi kontekstual, seperti port standar yang digunakan, distribusi pola query umum, serta daftar tujuan resmi untuk proses backup maupun replikasi, berfungsi sebagai landasan dalam membedakan lalu lintas sah dari aktivitas mencurigakan [10]. Integrasi ini berperan penting dalam menekan tingkat false positive, sehingga sistem deteksi menjadi lebih reliabel dalam lingkungan nyata. Meskipun demikian, evaluasi sistem deteksi secara realistis masih menghadapi kendala signifikan. Keterbatasan dataset publik yang memuat kombinasi representatif antara lalu lintas database benign dan skenario exfiltration yang disimulasikan mendekati kondisi operasional mengakibatkan proses evaluasi model sering kali kurang komprehensif. Akibatnya, validitas eksternal dari hasil penelitian menjadi terbatas, sehingga menimbulkan kebutuhan akan upaya lebih lanjut dalam pengembangan benchmark dataset yang lebih representatif terhadap skenario serangan dunia nyata. Penelitian ini bertujuan untuk mengatasi sebagian dari kesenjangan ini dengan fokus pada deteksi anomali data exfiltration, dengan penekanan khusus pada identifikasi pola yang relevan dengan data dari  database MariaDB/MySQL. Berdasarkan latar belakang masalah dan kesenjangan penelitian yang diidentifikasi, tujuan penelitian ini adalah sebagai berikut:
Membangun pipeline pra-pemrosesan data lalu lintas jaringan yang relevan untuk deteksi anomali data exfiltration, termasuk ekstraksi fitur berbasis waktu, frekuensi, panjang paket, dan informasi koneksi (Source/Destination/Protocol).
Mengembangkan dan melatih model deteksi anomali menggunakan algoritma Isolation Forest pada dataset lalu lintas jaringan yang dianggap benign (normal).
Mengevaluasi kinerja model Isolation Forest dalam mendeteksi anomali pada test set internal (benign) dan test set eksternal yang disimulasikan mengandung lalu lintas exfiltration database.
Mengembangkan dan mengintegrasikan fungsi kategorisasi dan penilaian risiko berbasis aturan yang spesifik untuk pola lalu lintas yang terkait dengan database exfiltration (MariaDB/MySQL), seperti deteksi protokol/port database, analisis volume transfer data besar, dan identifikasi tujuan mencurigakan.
Menganalisis hasil deteksi anomali Isolation Forest dikombinasikan dengan analisis pola spesifik database untuk memberikan visibilitas yang lebih baik terhadap potensi kejadian data exfiltration dari database.


METODE
Penelitian ini membangun dan mengevaluasi sistem deteksi anomali data exfiltration dengan fokus pada lalu lintas database (MariaDB/MySQL) menggunakan algoritma Isolation Forest. Berdasarkan klasifikasi umum, pendekatan yang digunakan dalam penelitian ini termasuk dalam kategori tindakan balasan detektif (detective countermeasures), karena berfokus pada identifikasi upaya exfiltration saat sedang berlangsung, bukan pada pencegahan di tahap awal [10], [25]. Metodologi ini mencakup deskripsi dataset yang digunakan, tahapan pra-pemrosesan data, detail algoritma deteksi anomali, serta metrik evaluasi kinerja model.

1. Dataset
Dataset yang digunakan dalam penelitian ini berasal dari simulasi lalu lintas jaringan yang mencakup aktivitas benign (normal) dan aktivitas yang disimulasikan sebagai data exfiltration. Dataset ini dirancang untuk merepresentasikan skenario lalu lintas jaringan yang umum di lingkungan perusahaan, dengan penambahan lalu lintas spesifik yang menyerupai upaya exfiltration data dari database. Sumber dataset berasal dari hasil simulasi maupun pengumpulan lalu lintas pada lingkungan jaringan terkontrol, yang dipublikasikan melalui Hugging Face pada repositori NADW Network Attacks Dataset (https://huggingface.co/datasets/onurkya7/NADW-network-attacks-dataset/tree/main/dataset/ benign). Secara keseluruhan terdapat lima file dataset yang dikategorikan sebagai benign (normal) serta satu file dataset yang disimulasikan mengandung lalu lintas exfiltration. Seluruh file disimpan dalam format CSV. Ukuran dan karakteristik dataset benign terdiri atas lima file terpisah dengan struktur kolom yang seragam. Setiap file memuat informasi lalu lintas jaringan mencakup atribut No., Time, Source, Destination, Protocol, Length, dan Info. Setelah seluruh file benign digabungkan, jumlah total record mencapai 22.084 dengan tujuh kolom. Lalu lintas benign mencerminkan variasi protokol umum, di antaranya QUIC, TCP, TLSv1.3, TLSv1.2, UDP, DNS, ICMPv6, ARP, MDNS, SSDP, HTTP, NTP, DHCP, dan IGMPv3, dengan QUIC serta TCP mendominasi distribusi. Kolom Length merepresentasikan ukuran paket data, sementara kolom Time menggambarkan waktu terjadinya komunikasi. Adapun kolom Source dan Destination berisi alamat IP maupun nama host atau layanan yang terlibat. Dataset exfiltration yang digunakan untuk pengujian eksternal berukuran lebih kecil, berjumlah 67 record, namun dirancang untuk mengandung pola lalu lintas yang secara spesifik mengindikasikan data exfiltration, terutama yang berasal dari serangan database atau transfer data besar. Struktur kolomnya identik dengan dataset benign, memungkinkan penggabungan dan perbandingan fitur yang konsisten.

Tabel 1 Ukuran dan Karakteristik Dataset


2. Pra-pemrosesan Dataset
Tahapan pra-pemrosesan data sangat krusial untuk menyiapkan data mentah agar sesuai untuk pelatihan model machine learning [32], [33]. Tahapan ini meliputi penggabungan dataset benign dilakukan dengan menyatukan lima file dataset benign (benign-*.csv) ke dalam satu DataFrame tunggal. Langkah ini bertujuan agar model dilatih pada representasi lalu lintas normal yang lebih luas dan beragam. Eksplorasi data awal (EDA) diterapkan pada setiap file dataset, baik benign maupun exfiltration, untuk memahami struktur data, mendeteksi nilai kosong, menganalisis statistik deskriptif, serta memperoleh gambaran awal distribusi data. Hasil EDA disimpan dalam format teks dan CSV, serta divisualisasikan dalam bentuk histogram distribusi numerik dan heatmap nilai kosong. Analisis ini mengonfirmasi bahwa kolom-kolom utama memiliki data yang cukup lengkap untuk digunakan pada tahap berikutnya. Khusus kolom Info, isinya bersifat deskriptif tekstual dengan variasi tinggi sehingga memerlukan pemrosesan berbasis Natural Language Processing (NLP) yang kompleks, yang berada di luar cakupan penelitian ini. Visualisasi data pra-pemrosesan menghasilkan distribusi nilai pada kolom kunci, yaitu Time, Source, Destination, Protocol, dan Length. Distribusi tersebut divisualisasikan menggunakan bar plot lima nilai teratas (Top 5) untuk mengidentifikasi entitas yang paling dominan sekaligus memperoleh pemahaman mengenai pola lalu lintas utama dalam dataset benign.

3. Rekayasa Fitur
Untuk meningkatkan kemampuan model dalam mendeteksi anomali, dilakukan rekayasa fitur untuk mengekstrak informasi yang lebih bermakna dari data lalu lintas jaringan. Proses rekayasa fitur bertujuan untuk mengekstrak pola-pola berguna dari data mentah agar dapat memisahkan antara kelas data yang berbeda, dalam hal ini antara lalu lintas normal dan anomali [10]. Fitur-fitur ini dirancang untuk menangkap aspek temporal, volumetrik, dan konektivitas yang relevan dengan deteksi anomali. Rekayasa fitur yang berfokus pada agregasi data dari waktu ke waktu merupakan langkah krusial, didasarkan pada prinsip bahwa serangan canggih sering kali tidak terdeteksi dalam satu sesi tunggal. Sebaliknya, pola anomali justru muncul dari rangkaian beberapa sesi yang terjadi secara sekuensial [13]. Tahapan rekayasa fitur meliputi:
Ekstraksi fitur timestamp dilakukan dengan mengonversi kolom Time ke dalam format datetime dan menurunkannya menjadi sejumlah fitur berbasis waktu, yaitu timestamp_unix (waktu dalam detik sejak epoch), hour (jam), day_of_week (hari dalam seminggu), dan minute (menit). Selanjutnya, data diurutkan berdasarkan timestamp_unix. Selain itu, dihitung pula time_diff (perbedaan waktu antar-paket berturut-turut) dan time_var (variansi time_diff dalam jendela bergulir, misalnya lima paket), yang berguna untuk mendeteksi anomali temporal seperti transfer data yang sangat cepat atau tidak beraturan.
Encoding fitur kategorikal diterapkan pada kolom Protocol, Source, dan Destination dengan menggunakan LabelEncoder, sehingga setiap nilai unik dikonversi menjadi representasi numerik. Encoder yang dilatih pada data training disimpan (protocol_encoder.pkl, source_encoder.pkl, destination_encoder.pkl) untuk menjaga konsistensi saat memproses data testing atau data baru. Nilai yang tidak ditemukan pada data training (unseen values) ditangani dengan pemberian label default, misalnya -1, selama proses transformasi data testing.
Ekstraksi fitur jaringan dilakukan untuk merepresentasikan pola komunikasi yang lebih mendetail. Beberapa fitur yang dihasilkan meliputi:
source_freq dan dest_freq, yaitu frekuensi kemunculan Source dan Destination dalam dataset yang telah dinormalisasi, berguna untuk mengidentifikasi entitas (IP/host) yang sangat aktif atau tidak biasa.
Length, yakni ukuran paket yang dikonversi menjadi numerik, dengan nilai kosong diisi nol.
length_log, berupa transformasi logaritmik pada Length (log1p) untuk mengurangi skewness data dan menghasilkan distribusi yang lebih normal.
length_category, yaitu kategorisasi Length ke dalam beberapa bin (small, medium, large, very_large) untuk menangkap variasi pola ukuran paket.
length_rolling_mean dan length_rolling_std, yaitu rata-rata dan standar deviasi Length dalam jendela bergulir (misalnya sepuluh paket) untuk mendeteksi perubahan mendadak dalam ukuran paket.
data_rate, yang dihitung sebagai Length / (time_diff + 1), digunakan untuk mengukur volume data per satuan waktu dan dapat menjadi indikator penting adanya aktivitas exfiltration.
Setelah rekayasa fitur, dataset benign yang telah diproses (df_processed) memiliki 21 kolom, termasuk fitur asli dan fitur baru.

4. Pembagian Dataset
Dataset benign yang telah melalui rekayasa fitur dibagi menjadi dua bagian: training set (80%) dan test set (20%) menggunakan fungsi train_test_split dari scikit-learn. Pembagian ini dilakukan secara acak dengan random_state=42 untuk memastikan reproduktibilitas. Awalnya dipertimbangkan stratifikasi berdasarkan kolom Protocol, namun karena adanya kelas dengan jumlah sampel yang sangat sedikit (< 2), stratifikasi dibatalkan dan digunakan split acak biasa. Data training (X_train_final) digunakan untuk melatih model Isolation Forest, sementara data testing internal (X_test_final) digunakan untuk mengevaluasi kinerja model pada data normal yang belum pernah dilihat sebelumnya.

Dataset exfiltration (df_test_ex) digunakan sebagai test set eksternal untuk mengevaluasi kemampuan model mendeteksi anomali yang sebenarnya (data exfiltration). Dataset ini diproses secara terpisah menggunakan fungsi pra-pemrosesan yang sama, namun menggunakan encoder dan scaler yang sudah dilatih pada data training benign untuk memastikan konsistensi transformasi fitur.

Fitur-fitur numerik yang relevan untuk model dipilih dari kedua dataset (X_train_final dan X_test_final) dan disimpan sebagai file CSV terpisah (X_train.csv, X_test.csv). Daftar fitur yang dipilih untuk pelatihan model adalah timestamp_unix, hour, day_of_week, minute, time_diff, time_var, protocol_encoded, source_encoded, dest_encoded, source_freq, dest_freq, Length, length_log, length_category, length_rolling_mean, length_rolling_std, dan data_rate.

5. Standardisasi Fitur
Sebelum melatih model Isolation Forest, fitur-fitur numerik pada data training (X_train_clean) distandardisasi menggunakan StandardScaler. Standarisasi mengubah nilai fitur sedemikian rupa sehingga memiliki rata-rata 0 dan standar deviasi 1. Langkah ini penting karena algoritma berbasis jarak atau yang sensitif terhadap skala, seperti Isolation Forest pada aspek pemisahan berdasarkan rentang nilai dapat dipengaruhi oleh rentang nilai fitur yang berbeda-beda. Scaler yang dilatih pada data training disimpan (scaler_final.pkl) dan kemudian diterapkan pada data testing internal dan data exfiltration eksternal untuk memastikan transformasi yang konsisten.

6. Algoritma Deteksi Anomali Isolation Forest
Isolation Forest dipilih sebagai algoritma deteksi anomali utama dalam penelitian ini karena beberapa alasan yang relevan dengan konteks deteksi data exfiltration:
Unsupervised learning menjadi salah satu alasan utama. Data exfiltration merupakan kejadian yang jarang terjadi, sehingga sulit memperoleh dataset berlabel dalam jumlah besar. Isolation Forest tidak memerlukan label anomali untuk pelatihan, sehingga cocok digunakan dalam skenario semacam ini.
Efisiensi dalam mengisolasi anomali juga menjadi keunggulannya. Berbeda dengan metode berbasis jarak, seperti K-Means, yang berusaha terlebih dahulu membentuk wilayah normal dan kemudian menandai titik di luar wilayah tersebut sebagai anomali, Isolation Forest secara langsung berupaya mengisolasi titik data yang menyimpang. Prinsipnya adalah anomali dideteksi sebagai vektor data yang memiliki panjang jalur rata-rata (average path length) terpendek. Untuk setiap pohon, jumlah cabang yang diperlukan untuk mengisolasi setiap titik data dihitung, dan rata-rata dari jumlah cabang ini mendefinisikan panjang jalur yang diharapkan (expected path length) untuk titik data tersebut [34]. Karena anomali cenderung lebih mudah dipisahkan, algoritma ini hanya memerlukan sedikit partisi pohon keputusan acak, sehingga prosesnya lebih efisien terutama untuk anomali yang berada jauh dari klaster data normal.
Skalabilitas merupakan kelebihan lain. Kompleksitas waktu Isolation Forest relatif rendah dibandingkan sejumlah algoritma deteksi anomali lainnya, sehingga algoritma ini layak digunakan pada dataset lalu lintas jaringan berukuran besar.
Ketiadaan asumsi distribusi data juga memberikan nilai tambah. Isolation Forest tidak mengharuskan data mengikuti distribusi tertentu, sebuah keuntungan karena lalu lintas jaringan umumnya tidak berpola Gaussian atau distribusi parametrik sederhana lainnya.
Kemampuan menangani data berdimensi tinggi menjadikannya semakin relevan. Meski lalu lintas jaringan biasanya memiliki banyak fitur, algoritma ini tetap dapat bekerja secara efektif pada kondisi tersebut.

Implementasi Model
Model Isolation Forest diimplementasikan menggunakan pustaka scikit-learn. Parameter kunci yang dikonfigurasi meliputi:
Parameter contamination ditetapkan sebesar 0,05 (5%) untuk mengestimasi proporsi anomali dalam data pelatihan. Walaupun dataset yang digunakan hanya berisi lalu lintas benign, penetapan nilai kontaminasi yang rendah memungkinkan model mengenali outlier pada data normal. Kondisi semacam ini bisa menjadi indikasi adanya perilaku yang tidak biasa meskipun belum tentu serangan exfiltration. Nilai kontaminasi tersebut dapat disesuaikan lebih lanjut berdasarkan domain knowledge maupun hasil eksperimen.
Parameter n_estimators ditentukan sebanyak 100, dengan pertimbangan bahwa semakin banyak pohon umumnya akan memberikan hasil yang lebih stabil.
Parameter max_features diatur sebesar 1,0 sehingga seluruh fitur digunakan dalam proses pembentukan setiap pohon.
Parameter bootstrap diset ke False, artinya sampel tidak diambil dengan penggantian saat membangun pohon.
Parameter random_state diberikan nilai 70 untuk memastikan hasil yang diperoleh dapat direproduksi dengan konsisten.
Parameter verbose diaktifkan dengan nilai 1 agar proses pelatihan menghasilkan keluaran yang dapat dipantau secara langsung.

Model dilatih (fit) pada data training yang telah distandardisasi (X_train_scaled). Setelah pelatihan, model Isolation Forest yang terlatih disimpan (isolation_forest_model.pkl) untuk digunakan dalam tahap pengujian dan inferensi data baru.

7. Deteksi Pola Spesifik Database
Untuk meningkatkan relevansi deteksi anomali dengan skenario exfiltration database, dikembangkan serangkaian fungsi kategorisasi dan deteksi pola berbasis aturan yang berfokus pada karakteristik lalu lintas yang terkait dengan database MariaDB/MySQL. Fungsi-fungsi ini bekerja secara independen dari model Isolation Forest tetapi hasilnya dapat diintegrasikan untuk memberikan konteks tambahan dan penilaian risiko yang lebih spesifik. Fungsi-fungsi ini meliputi:


Hasil dari fungsi-fungsi ini (kategori protokol, kategori tujuan, pola panjang, pola spesifik DB, tingkat risiko DB) ditambahkan sebagai kolom baru pada DataFrame hasil deteksi.

8. Penilaian Risiko Database (Database-Focused Risk Scoring)
Berdasarkan hasil prediksi anomali dari Isolation Forest dan kategori/pola spesifik database yang terdeteksi, dikembangkan skema penilaian risiko (database_risk_score) untuk setiap record lalu lintas. Skor risiko ini memberikan pandangan yang lebih bernuansa tentang potensi keterlibatan suatu kejadian lalu lintas dalam aktivitas exfiltration database, melengkapi hasil biner dari model Isolation Forest.  Skor ini merupakan kombinasi terbobot dari:
Hasil prediksi biner dari Isolation Forest (anomali vs normal).
Tingkat risiko dari kategorisasi protokol  database.
Tingkat risiko dari analisis pola panjang paket database.
Tingkat risiko dari kategorisasi tujuan database.
Kehadiran pola spesifik exfiltration database.
Jumlah pola spesifik yang terdeteksi.

9. Pengujian dan Evaluasi
Evaluasi kinerja sistem deteksi dilakukan dalam dua skenario utama. Pendekatan ini dirancang sebagai bagian dari mekanisme Proactive Threat Discovery, yaitu upaya yang tidak hanya berfokus pada deteksi ancaman secara real-time tetapi juga memungkinkan analisis retrospektif terhadap data historis untuk mengidentifikasi ancaman yang sebelumnya luput dari deteksi (Coutinho dkk. 2025). Pengujian internal dilakukan dengan menguji model Isolation Forest pada test set internal (X_test_scaled) yang bersumber dari data benign. Karena data ini seharusnya bebas dari anomali, metrik utama yang diperhatikan adalah akurasi dan False Positive Rate (FPR). FPR mengukur frekuensi kesalahan model dalam mengklasifikasikan lalu lintas normal sebagai anomali. Selain itu, confusion matrix dianalisis untuk melihat distribusi hasil prediksi. Pengujian eksternal dilakukan dengan menguji model Isolation Forest bersama analisis pola spesifik database pada dataset exfiltration (df_test_ex) yang telah disimulasikan mengandung anomali. Dataset ini diproses menggunakan scaler dan encoder yang sebelumnya dilatih dengan data benign. Metrik utama pada skenario ini adalah Detection Rate atau True Positive Rate, yang menunjukkan sejauh mana model berhasil mengenali lalu lintas exfiltration sebagai anomali. Hasil prediksi Isolation Forest kemudian digabungkan dengan hasil analisis pola spesifik database untuk memperoleh evaluasi gabungan.

Setelah itu, dilakukan evaluasi gabungan dengan mengompilasi hasil dari test set internal (benign) dan eksternal (exfiltration) guna menghasilkan metrik kinerja sistem secara menyeluruh. Beberapa indikator yang diperhatikan antara lain:



Hasil evaluasi (metrik dan confusion matrix) disimpan dalam file .pkl dan divisualisasikan menggunakan heatmap dan bar chart untuk memudahkan interpretasi.

10. Perangkat dan Pustaka
Penelitian ini diimplementasikan menggunakan bahasa pemrograman Python dengan dukungan sejumlah pustaka utama yang berperan pada berbagai tahap pengolahan data, pemodelan, dan evaluasi.
HASIL DAN PEMBAHASAN
Bagian ini menyajikan temuan utama dari analisis deteksi anomali data exfiltration menggunakan Isolation Forest yang diperkaya dengan analisis pola spesifik database, serta membahas interpretasi dan implikasi dari hasil tersebut.

1. Hasil Exploratory Data Analysis (EDA)
Tahap EDA awal pada dataset benign dan exfiltration memberikan pemahaman mendalam mengenai karakteristik data yang digunakan. Dataset benign yang digabungkan berjumlah 22,084 record, sementara dataset exfiltration hanya 67 record. Visualisasi Top 5 nilai terbanyak pada dataset benign.

Gambar 1 Visualisasi Top 5 nilai terbanyak pada dataset benign
Menunjukkan distribusi protokol yang didominasi oleh QUIC dan TCP, serta beberapa pasangan Source/Destination dan nilai Length yang paling sering muncul. Hal ini mengindikasikan pola komunikasi yang berulang dan umum dalam lalu lintas jaringan normal. 

Gambar 2 Visualisasi distribusi numerik benign 1 

Pada Gambar 2, distribusi numerik untuk Benign 1 memperlihatkan bahwa fitur No. mengikuti pola linier sesuai urutan record, sedangkan fitur Time menunjukkan konsentrasi pada rentang tertentu, khususnya di sekitar 379381 dan 394396. Hal ini menandakan adanya aktivitas benign yang lebih padat pada waktu-waktu tersebut. Sementara itu, distribusi Length didominasi oleh paket kecil di bawah 500 byte, dengan puncak tambahan pada kisaran 14001500 byte serta beberapa outlier hingga 4000 byte.

Gambar 3 Visualisasi distribusi numerik benign 2 
Pada Gambar 3, distribusi numerik Benign 2 kembali memperlihatkan pola linier pada fitur No., sementara fitur Time lebih bervariasi dengan puncak yang jelas pada interval awal sekitar 1150 dan kemudian menyebar hingga 1550. Distribusi Length sebagian besar berada pada ukuran sangat kecil (<200 byte), diikuti oleh cluster pada kisaran 14001500 byte, serta adanya outlier hingga 6000 byte yang menandakan keterlibatan paket besar dalam lalu lintas benign.

Gambar 4 Visualisasi distribusi numerik benign 3
Pada Gambar 4, distribusi numerik Benign 3 memperlihatkan penyebaran yang lebih merata pada fitur Time, dengan beberapa puncak kecil yang tersebar di rentang 21002500. Hal ini menunjukkan variasi aktivitas benign yang lebih stabil dibandingkan dua subset sebelumnya. Distribusi Length tetap didominasi oleh paket berukuran kecil di bawah 200 byte, dengan tambahan cluster di sekitar 1400 byte dan outlier yang mencapai 6000 byte.


Gambar 5 Visualisasi distribusi numerik benign 4

Pada Gambar 5, distribusi numerik Benign 4 memperlihatkan adanya dua cluster waktu yang menonjol, yaitu di sekitar 1850 dan 2050. Hal ini mengindikasikan intensitas lalu lintas benign yang lebih padat pada interval tertentu. Distribusi Length menampilkan pola serupa dengan subset sebelumnya, yakni dominasi paket kecil di bawah 200 byte, cluster pada kisaran 1400 byte, serta outlier hingga 6000 byte. Namun, terlihat juga distribusi tambahan di kisaran 28003000 byte yang kemungkinan merepresentasikan sesi komunikasi tertentu.

Gambar 6 Visualisasi distribusi numerik benign 5

Pada Gambar 6, distribusi numerik Benign 5 menunjukkan bahwa fitur Time relatif jarang dan hanya membentuk puncak pada interval sekitar 6750 dan 68006900. Hal ini menunjukkan intensitas lalu lintas benign yang lebih rendah dibanding subset sebelumnya. Distribusi Length tetap memperlihatkan pola dominan pada paket berukuran kecil (<200 byte), dengan tambahan cluster di sekitar 1400 byte serta outlier hingga 4000 byte.

Distribusi numerik menunjukkan karakteristik yang bervariasi antar file, menekankan pentingnya menggabungkan data benign untuk mendapatkan representasi yang lebih komprehensif.

2. Hasil Pra-pemrosesan Data dan Rekayasa Fitur
Proses rekayasa fitur berhasil mengekstraksi 16 fitur baru, menghasilkan total 21 kolom pada DataFrame yang diproses. Fitur-fitur baru ini mencakup informasi temporal (timestamp_unix, hour, day_of_week, minute, time_diff, time_var), representasi numerik dari fitur kategorikal (protocol_encoded, source_encoded, dest_encoded), dan fitur jaringan yang lebih kompleks (source_freq, dest_freq, length_log, length_category, length_rolling_mean, length_rolling_std, data_rate). Penambahan fitur-fitur ini bertujuan untuk memberikan representasi yang lebih kaya dan diskriminatif bagi model Isolation Forest.

Gambar 7 Visualisasi Top 5 distribusi fitur numerik

Visualisasi distribusi beberapa fitur kunci setelah rekayasa fitur pada data training  menunjukkan sebaran nilai pada fitur seperti Length, source_freq, dest_freq, length_log, data_rate, dan time_var. Beberapa fitur, seperti Length dan data_rate, menunjukkan distribusi yang sangat condong (skewed), membenarkan penggunaan transformasi logaritmik (length_log) dan standardisasi untuk membuat fitur-fitur ini lebih sesuai untuk model berbasis jarak atau distribusi.

Gambar 8 Visualisasi data spliting dan distribusi fitur

Pembagian dataset benign menjadi data training (17,667 records, 80%) dan testing (4,417 records, 20%) dilakukan tanpa stratifikasi karena adanya kelas protokol dengan jumlah sampel minimal. Visualisasi data split  mengkonfirmasi proporsi pembagian dataset dan menunjukkan distribusi timestamp_unix di kedua set, yang terlihat serupa, menandakan bahwa split berhasil mempertahankan karakteristik temporal data.

3. Hasil Pelatihan dan Pengujian Model Isolation Forest
Model Isolation Forest dilatih pada data training yang telah distandardisasi menggunakan StandardScaler. Model ini dikonfigurasi dengan contamination=0.05, menunjukkan asumsi bahwa sekitar 5% data dalam training set mungkin merupakan outlier. Hasil prediksi pada test set internal (benign) menunjukkan akurasi sebesar 0.9484 (94.84%). Confusion Matrix untuk pengujian.


Gambar 9 Confusion Matrix Internal 
Menunjukkan bahwa dari 4,417 record benign, sebanyak 4,189 berhasil diklasifikasikan dengan benar sebagai non-anomali (True Negative), namun terdapat 228 record yang salah diklasifikasikan sebagai anomali (False Positive). False Positive Rate (FPR) pada test set internal adalah 5.16% (228/4417). Tingkat FPR ini menunjukkan bahwa model menghasilkan sejumlah peringatan palsu pada lalu lintas normal, yang merupakan tantangan umum dalam deteksi anomali dan perlu dipertimbangkan dalam implementasi praktis. Pengujian eksternal dilakukan pada dataset exfiltration (67 record) yang diproses menggunakan scaler dan encoder yang sama. Hasil prediksi Isolation Forest pada data ini menunjukkan bahwa semua 67 record exfiltration terdeteksi sebagai anomali, menghasilkan Detection Rate (True Positive Rate) sebesar 1.0000 (100%). Ini adalah hasil yang sangat baik dalam mendeteksi anomali yang disimulasikan. Evaluasi gabungan dari test set internal dan eksternal memberikan gambaran kinerja model secara keseluruhan. Akurasi gabungan adalah 0.9492 (94.92%). Classification Report gabungan merangkum metrik untuk kedua kelas:
Benign (0): Precision 1.00, Recall 0.95, F1-score 0.97
Exfiltration (1): Precision 0.23, Recall 1.00, F1-score 0.37

Gambar 10 Hasil evaluasi gabungan 
Secara eksplisit menunjukkan:
True Negatives (TN): 4189 (Benign yang diprediksi Normal)
False Positives (FP): 228 (Benign yang diprediksi Anomali)
False Negatives (FN): 0 (Exfiltration yang diprediksi Normal)
True Positives (TP): 67 (Exfiltration yang diprediksi Anomali)

Hasil ini menegaskan bahwa model Isolation Forest sangat efektif dalam menangkap anomali (Detection Rate 100%) tetapi memiliki tantangan dalam membedakan anomali sebenarnya dari outlier pada data normal (FPR 5.16%, Precision untuk kelas Exfiltration hanya 0.23). Precision yang rendah pada kelas Exfiltration disebabkan oleh jumlah False Positive yang tinggi dibandingkan jumlah True Positive yang rendah (228 FP vs 67 TP). Ini berarti dari semua yang diprediksi sebagai anomali, hanya sebagian kecil yang benar-benar merupakan kasus exfiltration dalam dataset ini.

4. Hasil Deteksi Pola Spesifik Database dan Penilaian Risiko
Integrasi fungsi kategorisasi dan deteksi pola spesifik database memberikan lapisan analisis tambahan. Pengujian pada dataset exfiltration (df_test_ex) menggunakan fungsi advanced_database_exfiltration_detection menghasilkan dataframe hasil yang mencakup prediksi Isolation Forest, kategori protokol, pola panjang paket, kategori tujuan, pola spesifik database, tingkat risiko database, dan skor risiko database. Semua 67 record dalam dataset exfiltration terdeteksi sebagai anomali oleh Isolation Forest.


Tabel 1 Distribusi Protokol Database

Analisis distribusi kategori protokol database menunjukkan bahwa record exfiltration terbagi ke dalam beberapa kategori risiko, antara lain DATABASE_DIRECT_CRITICAL_RISK, DATABASE_ENCRYPTED_VERY_HIGH_RISK,DATABASE_EXPORT_HTTP_HIGH_RISK, DATABASE_TCP_HIGH_RISK, dan DATABASE_WEB_HIGH_RISK. Dari kelima kategori tersebut, risiko tertinggi ditunjukkan oleh DATABASE_DIRECT_CRITICAL_RISK, misalnya pada penggunaan protokol MYSQL/MARIADB atau koneksi langsung menuju port standar 3306. Pada kategori ini, skor prediksi anomali rata-rata mencapai 1.0 dengan skor risiko database sebesar 100, sesuai dengan ekspektasi untuk lalu lintas exfiltration database yang jelas dan kritis.

Tabel 2 Distribusi Pattern Database

Analisis distribusi pola database (db_patterns) mengidentifikasi beberapa kombinasi pola pada data exfiltration simulasi, antara lain LARGE_DATA_TRANSFER, DIRECT_DB_CONNECTION,CLOUD_STORAGE_TARGET,ENCRYPTED_BULK_TRANSFER, dan SUSPICIOUS_DESTINATION. Pola yang menggabungkan koneksi langsung ke database dengan transfer data berukuran besar, terutama menuju tujuan yang mencurigakan, menunjukkan skor risiko database tertinggi, yakni hingga 100.

Tabel 3 Distribusi Destination Database
Distribusi kategori tujuan database menunjukkan bahwa lalu lintas exfiltration ini ditujukan ke berbagai jenis tujuan, termasuk CLOUD_STORAGE_VERY_HIGH_RISK, DATABASE_SERVER_CRITICAL_RISK,EXTERNAL_SERVER_HIGH_RISK,FILE_SHARING_VERY_HIGH_RISK, dan SUSPICIOUS_DESTINATION_VERY_HIGH_RISK. Tujuan yang secara eksplisit terkait dengan database server atau tujuan eksternal/cloud storage yang mencurigakan mendapatkan skor risiko database yang tinggi. Skor risiko database yang dihitung memberikan nilai granular (0-100) untuk setiap record berdasarkan kombinasi prediksi anomali dan pola spesifik database. Rata-rata skor risiko database pada dataset exfiltration adalah 72.96, dan sebanyak 54 record (dari total 67) memiliki skor risiko  70. 

Tabel 4 Top 5 Highest Database Risk
Tampilan Top 5 record dengan skor risiko database tertinggi memperlihatkan record-record dengan kombinasi pola paling mencurigakan, seperti koneksi langsung ke tujuan yang terlihat seperti server backup atau situs eksternal dengan transfer data besar.


Gambar 11 Analisis visual database patterns
Visualisasi analisis database-specific patterns semakin memperjelas distribusi kategori protokol, pola database, dan kategori tujuan yang terdeteksi dalam data exfiltration simulasi. Bar plot distribusi kategori protokol dan pola database menunjukkan pola-pola yang paling sering muncul dalam lalu lintas exfiltration, sementara pie chart kategori tujuan menyoroti target umum dari serangan semacam ini. Bar plot Top 5 Unique Database Risk by Hostname (berdasarkan data simulasi) menunjukkan host yang paling sering terlibat dalam aktivitas berisiko tinggi.

5. Pembahasan
Hasil penelitian ini menunjukkan bahwa model Isolation Forest efektif dalam mendeteksi anomali dalam lalu lintas jaringan, dengan kemampuan menangkap 100% kasus exfiltration simulasi dalam dataset pengujian eksternal. Efisiensi algoritma ini dari sisi kompleksitas komputasi juga menjadikannya sesuai untuk aplikasi berskala besar maupun kebutuhan deteksi mendekati real time [26]. Tingkat Detection Rate yang tinggi ini sesuai dengan justifikasi pemilihan Isolation Forest, yaitu kemampuannya yang baik dalam mengisolasi outlier yang berbeda dari data normal. Keberhasilan ini sejalan dengan prinsip dalam deteksi anomali jaringan, di mana agregasi data dari beberapa sesi terbukti secara signifikan meningkatkan kemampuan deteksi, terutama terhadap serangan yang berlangsung lama atau terdistribusi dalam beberapa koneksi kecil [13]. Oleh karena itu, efektivitas fitur-fitur berbasis waktu dan frekuensi dalam penelitian ini merupakan konfirmasi dari sebuah pendekatan yang valid untuk menangkap anomali yang tersebar [13].  Temuan ini sejalan dengan praktik umum dalam deteksi anomali siber, di mana anomali volumetrik seperti transfer data dalam jumlah yang sangat besar secara konsisten diidentifikasi sebagai indikator utama aktivitas berbahaya. Pola anomali yang terjadi secara berulang dari sumber yang sama semakin memperkuat indikasi tersebut, yang sangat relevan untuk skenario serangan data exfiltration yang berkelanjutan [31]. Dalam konteks deteksi anomali, mendeteksi semua atau sebagian besar kejadian anomali yang sebenarnya meminimalkan False Negatives seringkali lebih penting daripada meminimalkan False Positives, terutama pada tahap awal investigasi keamanan.

Namun, hasil pengujian internal pada data benign menyoroti tantangan umum dalam deteksi anomali: tingkat False Positive yang relatif tinggi (5.16%). Ini berarti sistem akan menghasilkan sejumlah peringatan pada lalu lintas normal yang mungkin memerlukan analisis lebih lanjut oleh analis keamanan. Precision yang rendah pada kelas Exfiltration dalam evaluasi gabungan (0.23) secara langsung mencerminkan isu False Positive ini. Meskipun demikian, penelitian lain di bidang keamanan server telah menunjukkan bahwa dengan pemilihan fitur yang relevan seperti analisis asal geografis, jalur akses (path), dan ukuran lalu lintas model Isolation Forest mampu mencapai tingkat presisi yang sangat tinggi. Kemampuan untuk mencapai presisi tinggi ini mengindikasikan bahwa model dapat dikonfigurasi untuk meminimalkan peringatan yang tidak relevan, sebuah tantangan yang dalam penelitian ini diatasi melalui pendekatan hibrida dengan penilaian risiko spesifik database [30]. Mengingat dataset training hanya terdiri dari data benign, Isolation Forest mengidentifikasi outlier dalam data normal itu sendiri sebagai anomali. Outlier ini bisa jadi merupakan aktivitas normal yang jarang terjadi, bukan serangan.

Integrasi analisis pola spesifik database memberikan konteks berharga untuk menginterpretasikan hasil prediksi Isolation Forest, khususnya dalam skenario deteksi data exfiltration dari database. Dengan menggabungkan prediksi anomali (dari Isolation Forest) dengan deteksi pola berbasis aturan (protokol database, ukuran data besar, tujuan mencurigakan), sistem dapat memberikan skor risiko yang lebih informatif. Misalnya, lalu lintas yang diprediksi anomali oleh Isolation Forest dan juga menunjukkan pola koneksi langsung ke port database eksternal dengan transfer data besar akan mendapatkan skor risiko database yang sangat tinggi, menjadikannya prioritas utama untuk investigasi. Sebaliknya, lalu lintas yang diprediksi anomali tetapi tidak menunjukkan pola spesifik database mungkin merupakan jenis anomali lain atau False Positive. Pendekatan hibrida model statistik/machine  learning plus aturan domain seringkali lebih efektif dalam mengurangi False Positive yang tidak relevan dengan ancaman spesifik yang ingin dideteksi. Studi lain bahkan mengusulkan strategi pelengkap berupa deception, misalnya menciptakan dokumen palsu untuk menipu penyerang, yang terbukti dapat memperlambat atau menggagalkan proses data exfiltration [36].

Kelebihan Penelitian:
Demonstrasi penerapan Isolation Forest untuk deteksi anomali lalu lintas jaringan dengan hasil Detection Rate yang tinggi pada data exfiltration simulasi.
Pengembangan dan integrasi fungsi kategorisasi dan penilaian risiko yang spesifik untuk mendeteksi pola yang relevan dengan database exfiltration (MariaDB/MySQL), meningkatkan relevansi hasil deteksi anomali.
Penggunaan fitur rekayasa yang komprehensif, termasuk fitur temporal, frekuensi, dan volumetrik, yang penting untuk menangkap berbagai aspek anomali lalu lintas.

Keterbatasan Penelitian:
Dataset exfiltration yang digunakan berukuran kecil (67 record) dan disimulasikan.  Hal ini merupakan salah satu keterbatasan utama dalam riset keamanan siber, yaitu kelangkaan dataset publik yang berkualitas dan berskala besar [10].  Banyak dataset yang tersedia sering kali sudah usang dan tidak mampu merepresentasikan vektor serangan yang baru dan canggih. Akibatnya, peneliti sering kali terpaksa menggunakan dataset privat atau simulasi, yang membuat replikasi studi menjadi sulit [10]. Kinerja model mungkin berbeda pada dataset dunia nyata yang lebih besar dan kompleks dengan variasi teknik exfiltration yang lebih luas dan lalu lintas normal yang lebih beragam.
Dataset training hanya terdiri dari data benign. Dalam skenario dunia nyata, lalu lintas "normal" mungkin mengandung sejumlah kecil anomali yang tidak diketahui. Melatih model hanya pada data benign dapat mempengaruhi kemampuan model untuk menggeneralisasi.
Model Isolation Forest menghasilkan skor anomali, namun threshold binerisasi (contamination=0.05) perlu disesuaikan dengan hati-hati berdasarkan keseimbangan antara Detection Rate dan False Positive Rate yang dapat diterima oleh operasional keamanan.
Analisis pola spesifik database saat ini berbasis aturan sederhana. Metode yang lebih canggih misalnya graph-based analysis untuk koneksi atau sekuensial analysis untuk pola query mungkin dapat memberikan deteksi yang lebih akurat.
Model saat ini belum dirancang untuk mendeteksi serangan temporal. Penyerang yang canggih dapat menghindari deteksi dengan data exfiltration dalam fragmen-fragmen yang sangat kecil dalam periode waktu yang lama [29]. Karena setiap fragmen data terlalu kecil, kemungkinan besar akan dianggap sebagai false negative atau kebisingan (noise). Mengembangkan model yang mampu mengumpulkan dan menghubungkan fragmen-fragmen kecil ini dari waktu ke waktu merupakan tantangan riset yang signifikan untuk masa depan.

Implikasi Hasil
Hasil penelitian ini mengindikasikan bahwa Isolation Forest adalah algoritma yang menjanjikan untuk deteksi dini data exfiltration. Integrasi dengan analisis pola spesifik database sangat penting untuk konteks deteksi ancaman yang ditargetkan, membantu analis keamanan untuk memprioritaskan peringatan yang paling relevan dengan potensi kebocoran data sensitif. Untuk implementasi praktis, diperlukan penyesuaian parameter model khususnya contamination dan mungkin pasca-pemrosesan peringatan untuk mengurangi False Positive yang tidak relevan, misalnya dengan mengkorelasikan peringatan dari Isolation Forest dengan bukti tambahan dari analisis pola spesifik database atau sumber log lainnya. Penelitian selanjutnya dapat mengeksplorasi penggunaan dataset yang lebih realistis, teknik rekayasa fitur yang lebih canggih, dan algoritma deteksi anomali lainnya, serta metode untuk secara dinamis menyesuaikan threshold deteksi.

Kesimpulan
Penelitian ini berhasil mengimplementasikan sistem deteksi anomali data exfiltration pada lalu lintas jaringan menggunakan algoritma Isolation Forest, dengan fokus khusus pada identifikasi pola yang terkait dengan database exfiltration MariaDB/MySQL. Melalui serangkaian tahapan mulai dari pengumpulan dan pra-pemrosesan data benign, rekayasa fitur yang komprehensif mencakup aspek temporal, frekuensi, volumetrik, dan konektivitas, hingga pelatihan model Isolation Forest pada data normal, penelitian ini menunjukkan pendekatan yang menjanjikan dalam mendeteksi aktivitas data exfiltration.

Evaluasi model pada test set internal yang sepenuhnya benign menghasilkan akurasi 94.84%, namun dengan False Positive Rate (FPR) sebesar 5.16%. Ini mengindikasikan kemampuan model Isolation Forest dalam mengidentifikasi outlier dalam data normal, meskipun memunculkan tantangan terkait peringatan palsu. Hasil yang signifikan terlihat pada pengujian eksternal menggunakan dataset exfiltration simulasi, di mana model Isolation Forest mencapai Detection Rate sempurna 100%, berhasil mendeteksi semua record yang disimulasikan sebagai anomali. Evaluasi gabungan mengkonfirmasi kinerja tinggi dalam mendeteksi anomali (True Positive = 67, False Negative = 0) dengan akurasi gabungan 94.92%, meskipun diiringi oleh sejumlah False Positive (228) dari data benign. Precision yang rendah pada kelas Exfiltration (0.23) disebabkan oleh rasio FP terhadap TP.

Untuk memberikan konteks yang lebih relevan dengan skenario exfiltration database, penelitian ini mengintegrasikan analisis pola spesifik berbasis aturan. Fungsi kategorisasi protokol, pola panjang paket khususnya transfer data besar, kategori tujuan seperti server database, cloud storage, tujuan mencurigakan, dan deteksi kombinasi pola database berhasil mengidentifikasi karakteristik kritis dalam lalu lintas exfiltration simulasi. Skor risiko database yang dihasilkan dari kombinasi prediksi Isolation Forest dan analisis pola spesifik ini memberikan indikator yang lebih bernuansa mengenai potensi ancaman exfiltration dari  database, membantu dalam prioritisasi investigasi keamanan.

Secara keseluruhan, model Isolation Forest yang diperkaya dengan analisis pola spesifik database menunjukkan efektivitas tinggi dalam mendeteksi pola data exfiltration, khususnya yang menargetkan data dari database, dengan tingkat deteksi anomali yang sangat baik pada data simulasi. Meskipun tantangan False Positive tetap ada, pendekatan hibrida ini, yang menggabungkan model machine learning unsupervised dengan pengetahuan domain berbasis aturan, menawarkan cara yang efektif untuk memperkuat kemampuan sistem deteksi anomali dalam mengidentifikasi ancaman siber yang tersembunyi seperti data exfiltration. Penelitian di masa depan dapat fokus pada validasi dengan dataset dunia nyata yang lebih besar, penyempurnaan rekayasa fitur, eksplorasi algoritma lain, dan pengembangan metode adaptif untuk mengelola False Positive. Selain itu, penerapan praktis sistem deteksi anomali perlu disertai dengan penguatan keamanan pada platform pemeliharaan jarak jauh (telemaintenance). 

DAFTAR PUSTAKA
[1]	A. R. Hakim, K. Ramli, M. Salman, B. Pranggono, dan E. R. Agustina, ARKAIV: Predicting Data Exfiltration Using Supervised Machine Learning Based on Tactics Mapping From Threat Reports and Event Logs, IEEE Access, vol. 13, hlm. 2838128397, 2025, doi: 10.1109/ACCESS.2024.3524502.
[2]	J. King, G. Bendiab, N. Savage, dan S. Shiaeles, Data Exfiltration: Methods and Detection Countermeasures, dalam 2021 IEEE International Conference on Cyber Security and Resilience (CSR), Rhodes, Greece: IEEE, Jul 2021, hlm. 442447. doi: 10.1109/CSR51186.2021.9527962.
[3]	T. R. McIntosh dkk., Ransomware Reloaded: Re-examining Its Trend, Research and Mitigation in the Era of Data Exfiltration, ACM Comput. Surv., vol. 57, hlm. 140, 2024, doi: 10.1145/3691340.
[4]	M. Mundt dan H. Baier, Threat-Based Simulation of Data Exfiltration Toward Mitigating Multiple Ransomware Extortions, Digit. Threats Res. Pract., vol. 4, hlm. 123, 2022, doi: 10.1145/3568993.
[5]	F. R. Alzaabi dan A. Mehmood, A Review of Recent Advances, Challenges, and Opportunities in Malicious Insider Threat Detection Using Machine Learning Methods, IEEE Access, vol. 12, hlm. 3090730927, 2024, doi: 10.1109/ACCESS.2024.3369906.
[6]	A. Berady, M. Jaume, V. V. T. Tong, dan G. Guette, From TTP to IoC: Advanced Persistent Graphs for Threat Hunting, IEEE Trans. Netw. Serv. Manag., vol. 18, hlm. 13211333, 2021, doi: 10.1109/TNSM.2021.3056999.
[7]	U. Rauf, F. Mohsen, dan Z. Wei, A Taxonomic Classification of Insider Threats: Existing Techniques, Future Directions & Recommendations, J Cyber Secur Mobil, vol. 12, hlm. 221252, 2023, doi: 10.13052/jcsm2245-1439.1225.
[8]	H. Riggs dkk., Impact, Vulnerabilities, and Mitigation Strategies for Cyber-Secure Critical Infrastructure, Sensors, vol. 23, 2023, doi: 10.3390/s23084060.
[9]	Y. V. Bubnov dan N. N. Ivanov, Text analysis of DNS queries for data exfiltration protection of computer networks, Informatics, 2020, doi: 10.37661/1816-0301-2020-17-3-78-86.
[10]	B. Sabir, F. Ullah, M. A. Babar, dan R. Gaire, Machine Learning for Detecting Data Exfiltration: A Review, 21 Maret 2021, arXiv: arXiv:2012.09344. doi: 10.48550/arXiv.2012.09344.
[11]	E. Papadogiannaki dan S. Ioannidis, Acceleration of Intrusion Detection in Encrypted Network Traffic Using Heterogeneous Hardware, Sensors, vol. 21, 2021, doi: 10.3390/s21041140.
[12]	W. Song dkk., A Software Deep Packet Inspection System for Network Traffic Analysis and Anomaly Detection, Sensors, vol. 20, 2020, doi: 10.3390/s20061637.
[13]	D. Willems, K. Kohls, B. Van Der Kamp, dan H. Vranken, Data Exfiltration Detection on Network Metadata with Autoencoders, Electronics, vol. 12, no. 12, hlm. 2584, Jun 2023, doi: 10.3390/electronics12122584.
[14]	O. Abualghanam, H. Alazzam, B. Elshqeirat, M. Qatawneh, dan M. A. Almaiah, Real-Time Detection System for Data Exfiltration over DNS Tunneling Using Machine Learning, Electronics, vol. 12, no. 6, hlm. 1467, Mar 2023, doi: 10.3390/electronics12061467.
[15]	H. Ichise, Y. Jin, dan K. Iida, RPZ-Based Suspicious Direct Outbound DNS Traffic Detection Mechanism With Adaptive Policy Updates, IEEE Access, vol. 13, hlm. 3069430704, 2025, doi: 10.1109/ACCESS.2025.3542234.
[16]	J. S. Gmez, J. Gallego-Madrid, R. Sanchez-Iborra, J. Santa, dan A. Gmez-Skarmeta, Impact of SCHC Compression and Fragmentation in LPWAN: A Case Study with LoRaWAN, Sensors, vol. 20, 2020, doi: 10.3390/s20010280.
[17]	D. Uroz dan R. J. Rodrguez, Characterization and Evaluation of IoT Protocols for Data Exfiltration, IEEE Internet Things J., vol. 9, hlm. 1906219072, 2022, doi: 10.1109/JIOT.2022.3163469.
[18]	J. A. Abbasi, H. H. Gharakheili, Q. Raza, C. Russell, dan V. Sivaraman, Monitoring Enterprise DNS Queries for Detecting Data Exfiltration From Internal Hosts, IEEE Trans. Netw. Serv. Manag., vol. 17, hlm. 265279, 2020, doi: 10.1109/TNSM.2019.2940735.
[19]	M. Kombrink, Z. Geradts, dan M. Worring, Image Steganography Approaches and Their Detection Strategies: A Survey, ACM Comput. Surv., vol. 57, hlm. 140, 2024, doi: 10.1145/3694965.
[20]	L. M. Metcheka dan R. Ndoundam, Distributed data hiding in multi-cloud storage environment, J. Cloud Comput., vol. 9, 2020, doi: 10.1186/s13677-020-00208-4.
[21]	B. Alouffi, M. Hasnain, A. Alharbi, W. Alosaimi, H. Alyami, dan M. Ayaz, A Systematic Literature Review on Cloud Computing Security: Threats and Mitigation Strategies, IEEE Access, vol. 9, hlm. 5779257807, 2021, doi: 10.1109/ACCESS.2021.3073203.
[22]	X. Cai, H. Zhang, C. M. Ahmed, dan H. Koide, Detecting Advanced Persistent Threat Exfiltration With Ensemble Deep Learning Tree Models and Novel Detection Metrics, IEEE Access, vol. 13, hlm. 8180381822, 2025, doi: 10.1109/ACCESS.2025.3567772.
[23]	S. Sachintha, N.-A. Le-Khac, M. Scanlon, dan A. P. Sayakkara, Data Exfiltration through Electromagnetic Covert Channel of Wired Industrial Control Systems, Appl. Sci., 2023, doi: 10.3390/app13052928.
[24]	D. Preuveneers dan W. Joosen, Sharing Machine Learning Models as Indicators of Compromise for Cyber Threat Intelligence, J. Cybersecurity Priv., vol. 1, no. 1, hlm. 140163, Feb 2021, doi: 10.3390/jcp1010008.
[25]	A. Lal, A. Prasad, A. Kumar, dan S. Kumar, Data Exfiltration: Preventive and Detective Countermeasures, SSRN Electron. J., 2022, doi: 10.2139/ssrn.4031852.
[26]	M. Elnour, N. Meskin, K. Khan, dan R. Jain, A Dual-Isolation-Forests-Based Attack Detection Framework for Industrial Control Systems, IEEE Access, vol. 8, hlm. 3663936651, 2020, doi: 10.1109/ACCESS.2020.2975066.
[27]	H. Xu, G. Pang, Y. Wang, dan Y. Wang, Deep Isolation Forest for Anomaly Detection, IEEE Trans. Knowl. Data Eng., vol. 35, hlm. 1259112604, 2022, doi: 10.1109/TKDE.2023.3270293.
[28]	K. Sadaf dan J. Sultana, Intrusion Detection Based on Autoencoder and Isolation Forest in Fog Computing, IEEE Access, vol. 8, hlm. 167059167068, 2020, doi: 10.1109/ACCESS.2020.3022855.
[29]	J. Suaboot, A holistic approach for efficient host-based data exfiltration detection, thesis, RMIT University, 2024. doi: 10.25439/rmt.27599232.
[30]	A. Ragil Saputro, N. Nurchim, dan V. Atina, IDENTIFIKASI ANOMALI KEAMANAN SERVER NGINX MENGGUNAKAN ALGORITMA ISOLATION FOREST, JATI J. Mhs. Tek. Inform., vol. 9, no. 2, hlm. 24652471, Mar 2025, doi: 10.36040/jati.v9i2.13110.
[31]	D. B. Santoso dan Y. Wahyuni, DETEKSI ANOMALI PADA LOG SISTEM WEB SERVER MENGGUNAKAN ISOLATION FOREST ANOMALY DETECTION IN WEB SERVER SYSTEM LOGS USING ISOLATION FOREST, J. Apl. Bisnis Dan Komput., vol. 4, no. 3, hlm. 9096, Nov 2024, doi: 10.33751/jubikom.v4i3.10941.
[32]	H. R. Jones, T. Mu, A. C. Popescu, dan Y. Sulehman, Adapting Data-Driven Techniques to Improve Surrogate Machine Learning Model Performance, IEEE Access, vol. 11, hlm. 2390923925, 2023, doi: 10.1109/ACCESS.2023.3253429.
[33]	X.-Y. Liu, S. Du, F. Lv, H. Xue, J. Hu, dan T. Li, A Pre-trained Data Deduplication Model based on Active Learning, ArXiv, vol. abs/2308.00721, 2023, doi: 10.48550/arXiv.2308.00721.
[34]	J. Lesouple, C. Baudoin, M. Spigai, dan J. Tourneret, Generalized isolation forest for anomaly detection, Pattern Recognit Lett, vol. 149, hlm. 109119, 2021, doi: 10.1016/j.patrec.2021.05.022.
[35]	A. C. Coutinho dan L. V. D. Arajo, MICRA: A Modular Intelligent Cybersecurity Response Architecture with Machine Learning Integration, J. Cybersecurity Priv., vol. 5, no. 3, hlm. 60, Agu 2025, doi: 10.3390/jcp5030060.
[36]	O. T. Taofeek, M. Alawida, A. Alabdulatif, A. E. Omolara, dan O. I. Abiodun, A Cognitive Deception Model for Generating Fake Documents to Curb Data Exfiltration in Networks During Cyber-Attacks, IEEE Access, vol. 10, hlm. 4145741476, 2022, doi: 10.1109/ACCESS.2022.3166628.
